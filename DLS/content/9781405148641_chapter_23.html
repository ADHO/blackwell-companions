<div class="content">
                  <h2 class="normal">23. 
                     <h2 class="normal">Cybertextuality and Philology</h2>
                  </h2>
                  <span style="font-weight:bold;">Ian Lancashire</span>
                  
                  <a name="_h55"></a><a name="_h56"></a>
                  
                  
                  
                  <a name="ss1-6-4_h0"></a><h2 class="normal">What is Cybertextuality?</h2>
                  
                  <p>Employed sometimes as a synonym for "digital text" and "reading machine," the term "cybertext" is any document viewed from the perspective of the theory or study of communication and control in living things or machines.
                     This theory emerged in 1948 in a book titled <i>Cybernetics</i> by the American mathematician Norbert Wiener (1894–1964). Cybernetics derives from the Greek <i>kubernetes</i>, meaning "steersman." Wiener calls it "the theory of messages" (<a href="#ss1-6-4_b38">Wiener 1950</a>: 106; <a href="#ss1-6-4_b27">Masani 1990</a>: 251–2) because it theorizes communications among animals and machines. I refer to Wienerian messages in any cybernetic system
                     as cybertexts (<a href="#ss1-6-4_b22">Lancashire 2004</a>). They come in pairs, an utterance-message and its feedback-response, both of them transmitted through a channel from sender
                     (speaker/author) to receiver (listener/reader) through an ether of interfering noise. Five control modules (sender, channel,
                     message, noise, and receiver) affect forward-messaging (the utterance) and messaging-feedback (the model) through this cybernetic
                     channel. Wiener's insight, and the raison-d'être of cybernetics, is that anyone authoring a message steers or governs its making by feedback from those who receive it.
                     Norbert Wiener defined the mechanics of cybernetics, and Claude Shannon, who founded information science, devised its equations.
                  </p>
                  
                  <p>Many sciences, having lionized the brainchild of Wiener and Shannon for a time, went on with their business as usual, and
                     the digital humanities have been no exception. The postmodernist François Lyotard in <i>The Postmodern Condition</i> derived his "agonistic" model for communication and his "theory of games" (<a href="#ss1-6-4_b11">Galison 1994</a>: 258) from cybernetics. Donna Haraway's cyborg manifesto also builds on cybernetics. Postmodernists tend to draw on cybernetics
                     as a fund of metaphors, but the mechanics of messages, whether they are instructions relayed to a missile system by radar,
                     or poems, have measurable feedback. Under a decade ago, Espen Aarseth coined the term "cybertext" in his book of the same name. All cybertexts, Aarseth says, are "ergodic," a word that Wiener uses and that etymologically means "path of energy or work": a cybertext requires a reader to do physical work aside from turning pages and focusing his eyes. By throwing stalks (if
                     reading the I Ching) or managing a computer process with a mouse or a keyboard, the human operator-reader partners with an
                     active and material medium and so becomes part of a figurative reading "machine for the production of variety of expression" (1997: 3). To Aarseth, the cybertext is that machine. It includes the reader, his request, and a computer that parses his
                     request, sends it to a "simulation engine" that assembles digital objects for a "representation engine" that passes it along to a synthesizer or interface device, which returns feedback to the reader. There is no author or noise
                     in Aarseth's diagram. It cuts Wiener's system in half.
                  </p>
                  
                  <p>Another computing humanist who cites Norbert Wiener is Katherine N. Hayles. In her <i>How We Became Posthuman: Virtual Bodies in Cybernetics, Literature, and Inform-atics</i> (1999), Hayles also drops Wiener's sender/author in order to focus on his receiver/observer, following the concept of autopoesis,
                     a self-organizing principle that she finds in the cybernetic research of the South American scientist, Humberto Maturana.
                     He observes that, in seeing things, a frog "does not so much register reality as construct it," a theme he generalizes in the maxim, "Everything said [in a cybernetic system] is said by an observer" (xxii, cited by <a href="#ss1-6-4_b17">Hayles 1999</a>: 135). That is, living things do not receive messages passing through a noiseless channel in the state that they were sent.
                     In constructing or modeling messages, readers change what authors utter: new messages result. Maturana, Hayles, and many others
                     neglect the sender/author, although authors and readers are one and the same because authors receive and construct their own
                     utterances.
                  </p>
                  
                  <p>Cybertextuality systematically applies cybernetics to speaking and writing as well as listening and reading. Consider how
                     the five things studied by literary researchers parallel the five modules of cybernetics. There are <i>authors</i> of texts (studied in stylistics, biography, and authorship attribution; <a href="#ss1-6-4_b23">Lancashire 2005</a>), <i>readers</i> of texts (studied in theory, criticism, and usability studies), <i>texts</i> themselves (studied in close reading and encoding), and the language technologies and media, which together form a channel,
                     that govern their transmission through wear-and-tear that might be called literary <i>noise</i> (studied in stemmatics, textual criticism, and media).
                  </p>
                  
                  <p>This five-part model supports two kinds of messages or cybertexts: an outward message, from author to reader, that is encoded
                     with redundancy to resist the damaging effects of noise; and a feedback response that variously reflects the state in which
                     the original message arrived. Authors bring to bear all the techniques of grammar and rhetoric to repeat and vary what they
                     want to say so that the reader can understand it. Cybertextually speaking, authors encode redundant data in their cybertexts
                     so that they can withstand interference by noise and can reach readers comprehensibly. The thought that an author hopes to
                     communicate is the content of a cybertext, and the degree of its rhetorical treatment (the encoding) marks how dense that
                     content or information will be. (Sometimes the content is its encoding.) As redundancy increases, the information density
                     of a cybertext (in information science, its entropy) lessens. Inadequate encoding, and persistent extraneous noise, may lead
                     a reader to mistake or doubt what a dense, underspecified text says. Textual criticism studies noise, that is, the effects
                     that the channel itself (e.g., a scriptorium, a printing press, a noisy room) and extraneous interference (e.g., the interpretative
                     readings that scribes and compositors sometimes impose on texts that they are copying) have on cybertexts. The complementary
                     feedback cybertext, which registers that the outgoing message has been received, can be used to detect errors in transmission.
                     The humanities enshrine this reader-to-writer, receiver-to-sender feedback in teaching, discussion, and peer-review. The digital
                     humanities supplement the human reader-receiver by developing text-analysis software that feeds back semi-automatic analyses
                     of its texts. Working with the information sciences, the digital humanities do not leave the reader-receiver to chance but
                     build one. In this respect, computing humanists bring together human and machinic communications to form a cybernetic package.
                  </p>
                  
                  
                  <a name="ss1-6-4_h1"></a><h2 class="normal">Cybertextual Simulations</h2>
                  
                  <p>Cybertextuality, to recapitulate, is a subset of cybernetics that studies the messaging and feedback modules — author, text, channel/media, noise, and reader — of languages and literatures. It is difficult to analyze this system directly because authors create reclusively. Computing
                     humanists, for that reason, employ purpose-built simulations. Simulators enable us experimentally to test the theory and practice
                     of cybertexts. Because this is an unusual way of thinking about what we are doing, I will break down the simulations by cybernetic
                     module: cybertext, receiver/reader, noise, channel, and author/sender.
                  </p>
                  
                  <p>Poetry generators, some computer text games, and chatterbots are artificial or simulated author-agents. We can study how they
                     implement natural language or we can analyze the cybertexts that they make, which include poems, stories, and conversation.
                     The software simulates authors and outputs algorithmic cybertexts. The last Loebner Prize for the best chatterbot, in 2005,
                     went to Rollo Carpenter for his <i>Jabberwacky</i>. Authoring software often spoofs writing. For instance, three MIT students, Jeremy Stribling, Max Krohn, and Dan Aguayo,
                     devised SCIgen — An Automatic CS Paper Generator, "a computer program to generate nonsensical research papers, complete with 'context-free grammar,' charts and diagrams." They submitted "Rooter: A Methodology for the Typical Unification of Access Points and Redundancy" to the ninth World Multi-Conference on Systematics, Cybernetics, and Informatics, which initially accepted it as a non-reviewed
                     paper.
                  </p>
                  
                  <p>Media studies treat the cybernetic channel. Marshall McLuhan conflated the Wienerian cybertext with the channel when he said
                     that the medium was the message. Mark Federman of the McLuhan Program explains this equation: "We can know the nature and characteristics of anything we conceive or create (medium) by virtue of the changes — often unnoticed and non-obvious changes — that they effect." Within cybertextuality, most research on the channel's impact on the utterances it carries takes place in usability studies.
                     What affordances, an information scientist asks, does the channel have with respect to the communication of a message? Computer-mediated mail, webcasting, cell phone, printed book, posted letter, meeting, and lecture instantiate differently
                     this cybernetic channel. The Knowledge Media Design Institute (Toronto) produces software named <i>ePresence Interactive Media</i> that enables remote viewers to take part in webcasts. Because computer workstations are themselves a channel, cybertextuality
                     mainly analyzes how novel electronic media affect authoring and reading. Simulation of non-electronic channels by software
                     is uncommon.
                  </p>
                  
                  <p>The digital humanities applies what we know of cybertext noise to model how a text metamorphoses over time. Computer-based
                     stemmatics reconstructs the timeline of a work as noise alters it, state by state, in moving through the channel we call manuscript
                     scriptoria and printed editions. Cladograms from Phylogenetic Analysis using Parsimony, software devised by the Canterbury
                     Tales project, gives a schematic tree of snapshots of a cybertext as it falls through time from one state to another (<a href="#ss1-6-4_b8">Dunning 2000</a>). Stephen E. Sachs' <i>The Jumbler</i>, which algorithmically mixes up every letter in a word but the first and the last, simulates noise. A sentence muddled in
                     this way can still be read. (<i>A snceente muldded in tihs way can sltil be raed</i>.) If our subject of research were noise itself, we would study how living scribes alter their exemplars in copying them.
                     When people retell events from memory after a time, they suffer from another kind of noise, what psychologists name the post-event
                     misinformation or retelling effect. Collational software can readily identify and time-stamp the emergence and reworking of
                     textual variants. This cybertextual experiment would help classify the kind of errors that scribes make and complicate over
                     time.
                  </p>
                  
                  <p>We create text-analysis programs that act as artificial or simulated readers to give feedback on cybertexts. By running Robert
                     Watt's <i>Concordancer</i> on any work, for example, we act as stand-ins for the work's author in remitting it to a computer reader for feedback. In
                     both simulations, we control, as far as possible, the noise of the simulated channel by choosing the most error-free common
                     carrier of our time: the workstation. For all our complaining, it is a reliable device, enabling many people to repeat the
                     same cybertextual experiment many times, in many places. This reliability allows us to do experiments together and to agree
                     on criteria whereby our research can be falsified.
                  </p>
                  
                  <p>Some cybertextual simulators appear impoverished when compared to human beings. Concordances output indexes and rearrange
                     a text rather than respond, like a reader, to one. The Jumbler, Jabberwacky, and SCIgen play word-games. Other simulators
                     devised by artificial intelligence and computational linguistics teach us much about communication and can stand in routinely
                     for human beings. Machine-translation (MT) systems read text in one language and feed back a version of that text in another
                     language. The morphological, lexical, syntactic, and semantic analyzers in a classical MT system have helped us understand
                     how language works. Recent story-generation programs like MakeBelieve from MIT Media Lab use Open Mind, a web database of
                     710,000 common-sense facts, as well as ConceptNet, a semantic network built on top of it (<a href="#ss1-6-4_b25">Liu and Singh 2002</a>). The infrastructure by which it assembles little coherent stories from sample opening sentences uses a constituent structure
                     parser, fuzzy matching, and a sentence generator. If these simulations or modeling programs had access to the same high-performance
                     computing resources employed in protein-folding, cosmology, weather prediction, and airframe design, the results might be
                     still more impressive.
                  </p>
                  
                  
                  <a name="ss1-6-4_h2"></a><h2 class="normal">The Cybertextual Cycle</h2>
                  
                  <p>The digital humanities have a helpful cognate discipline in cognitive psychology, which experimentally analyzes how the living
                     speaker-writer and the living listener-reader manage their language, both message and feedback, in a noisy world. The digital
                     humanities also analyze this process, but only indirectly, through our stored cybertexts alone.
                  </p>
                  
                  <p>The journal <i>Brain</i> last year published Peter Garrard's remarkable study of works by the English novelist Iris Murdoch as she succumbed to Alzheimer's
                     disease. Tests during her final years revealed a mild impairment of working memory (in digit span). After her death in 1999,
                     an autopsy found "profound bilateral hippocampal shrinkage." A healthy hippocampus is necessary for working memory. By generating the simplest form of text analysis — word-frequency lists from early, middle, and last novels — Garrard found an increasing lexical and semantic "impoverishment." Although <i>Jackson's Dilemma</i>, her last novel, showed no deterioration in syntax, it had a "more restricted vocabulary," that is, a smaller number of word-types (different words) and, thus, a greater rate of lexical repetition. Her earliest novel
                     exhibited about 5,600 word-types per 40,000 words, but in <i>Jackson's Dilemma</i> that ratio had fallen to 4,500, a drop of 20 percent. The final novel was not unreadable but critics described it as transparent,
                     economical, scant of explanation, and "distrait" in narrative. The medical tests and autopsy make predictions that the computer text substantiates. Together, they tie semantic
                     complexity and information density to the size of working memory and to the hippocampus. Garrard's case study shows that evidence
                     of cognitive affects in language processing, those backed up experimentally, help explain the lexical minutiae of authoring
                     at work, whether in making or remaking/reading text. These low-level mechanics are beyond our ability to observe consciously
                     in ourselves as we utter phrases and sentences, but we can access them experimentally with the help of special tools.
                  </p>
                  
                  <p>The language powers movingly described in the case of Iris Murdoch have two cognitive staging grounds: working memory, where
                     we consciously recall spoken language and written images of text so that we can work with them; and the big black box of unconscious
                     neurological functions that working memory accesses but that we cannot access directly. Alan Baddeley, an English cognitive
                     psychologist, proposed working memory in the mid-1970s. It remains today the standard theoretical model. In 2003 he published
                     a schematic flowchart of how we consciously use working memory to speak aloud something we have read or heard (<a href="#ss1-6-4_f1">Figure 23.1</a>).
                  </p>
                  
                  <p><br><a name="ss1-6-4_f1"></a>
                     <img src="9781405148641_chapter_23_f1.gif">
                     <b>
                        
                        </b></p>
<p> <b>Figure 23.1 </b> Baddeley's proposed structure for the phonological loop. <i>Source:</i> Baddeley, Alan, 2003, "Working Memory and Language: An Overview." <i>Journal of Communication Disorders</i> 36.3: 189–203. Reprinted with permission from Elsevier.
                        </p>
                     <br>
                  
                  <p>We consciously place or retrieve a visually seen sentence into a visual short-term store, recode it elsewhere into phonological
                     form, and then send that recoded data to an output buffer for pronouncing. The visual short-term store is a visuo-spatial
                     sketchpad in working memory. Nothing in this visual short-term store can be processed as speech unless it is converted to
                     auditory form. Mentally, we process language as speech, not writing. That is why sudden heard speech always gains our immediate
                     attention: auditory data do not need to be re-encoded to access working memory. When we hear speech, we place it in another
                     short-term store, this time a phonological one that Baddeley called the phonological loop. An utterance enters this short-term
                     store and exits from it after a short time, unless we consciously rehearse or refresh it, as if memory were a loop. Then we
                     send it to an output buffer for pronouncing.
                  </p>
                  
                  <p><br><a name="ss1-6-4_f2"></a>
                     <img src="9781405148641_chapter_23_f2.gif">
                     <b>
                        
                        </b></p>
<p> <b>Figure 23.2 </b> Baddeley's three-component model of working memory. <i>Source:</i> Baddeley, Alan, 2003, "Working Memory and Language: An Overview." <i>Journal of Communication Disorders</i> 36.3: 189–203. Reprinted with permission from Elsevier.
                        </p>
                     <br>
                  
                  <p>Another schematic by Baddeley identifies the model's functions — input, analysis, short-term store, recoding, and output buffer — as being fluid (<a href="#ss1-6-4_f2">Figure 23.2</a>). The contents come and go dynamically. However, the model draws on the brain's crystallized systems, which interpret what
                     images signify linguistically, give long-term memory of events, and enable phonological, lexical, grammatical, and syntactic
                     analysis. We store the content in these systems and it is available for use over a long period of time. In the classical model,
                     Baddeley's language functions correspond, more or less, to locations in the brain. These locations and their language functions
                     have been disputed. The classical Lichtheim-Geschwind model has the angular gyrus recoding phonologically visual data from
                     the visual cortex at the back of the brain, passing it to Wernicke's area, which processes phonemic language semantically
                     and in turn sends it to Broca's area, which shapes semantic text into syntactic form in preparation for articulation (<a href="#ss1-6-4_b13">Geschwind 1979</a>). Recently, however, subcortical areas in the basal ganglia have been shown to regulate cognitive sequencing, including the
                     motor controls that produce speech. Thus the phonological loop in working memory, which represents words as articulated, depends
                     on the basal ganglia. Working memory uses multiple locations simultaneously, but it is associated with the hippocampus in
                     the forebrain.
                  </p>
                  
                  <p>Baddeley's flowchart is a torus, a looping cybernetic channel for cybertext. What goes out as uttered speech authored by us
                     in turn enters working memory as received heard speech to which we will give, in turn, feedback. Cognitive language processing
                     is thus a cybertextual message-feedback system.
                  </p>
                  
                  <p>Creating takes place in the black box outside working memory. Normally we are not conscious of what we say before we say it.
                     Few people script an utterance in working memory before uttering. The same holds true for written output, for although we
                     may hear silently the text as we are storing it on screen or paper, we seldom preview it in working memory before typing it.
                     There is often surprise in discovering what we have just said. As Baddeley's first flowchart shows, we are also not aware
                     of what goes on in boxes A and D, the visual and phonological analyses of input sense data, before we store those analyses
                     in working memory. Between the visual and auditory input, and our conscious reception of image and speech in working memory,
                     there are two black boxes in which we actively construct what we think we see and hear. The so-called McGurk effect tells
                     us that we unconsciously subvocalize a model of what someone else is saying. We then "hear" only what we analyze we are hearing. The last one to utter any heard utterance, in effect, is the hearer-observer. The McGurk
                     experiment is described by <a href="#ss1-6-4_b24">Philip Lieberman 2000</a>: (57, citing <a href="#ss1-6-4_b28">McGurk and MacDonald 1976</a>):
                  </p>
                  
                  <blockquote>
                     <p>The effect is apparent when a subject views a motion picture or video of the face of a person saying the sound [ga] while
                        listening to the sound [ba] synchronized to start when the lips of the speaker depicted open. The sound that the listener
                        "hears" is neither [ba] or [ga]. The conflicting visually-conveyed labial place-of-articulation cue and the auditory velar place
                        of articulation cue yield the percept of the intermediate alveolar [da]. The tape-recorded stimulus is immediately heard as
                        a [ba] when the subject doesn't look at the visual display.
                     </p>
                  </blockquote>
                  
                  <blockquote>
                     <p>The listener hears a sound that no one uttered. Cybertextually, a receiver co-authors, by virtue of his cognitive interpretation
                        of auditory and visual inputs, a message from the sender.
                     </p>
                  </blockquote>
                  
                  <p>It is not unreasonable to believe that the McGurk effect applies to all heard and seen words, from whatever source. If we
                     utter speech unselfconsciously, not knowing what it will be until we experience it ourselves — that is, if we do not script our words in working memory before we say them (and to do so would be to reduce our conversation
                     to an agonizingly slow, halting process) — and if we receive our own utterance auditorily (listening to our words as we speak them), then our brain must unconsciously
                     model those words before they fall into our working memory. Whenever we author speech, therefore, we hear it at the same time
                     as our listeners. Or, when we write something down, that utterance also reaches us through the visual cortex and must be decoded
                     and analyzed cognitively before we can receive it in working memory. Cybertextually, the speaker receives his own message
                     at the same time that his listener or his reader does. A message is always cognitively constructed by its receivers, and the
                     author is always one of these constructing observers. A message passes through, simultaneously, different cybernetic channels
                     for its sender and for every receiver. One goes back to the author, and others to audience members and readers.
                  </p>
                  
                  <p>The author's self-monitoring is not much studied. Feedback for every utterance is of two kinds. The author's initial cognitive
                     construction of what he hears himself say or sees himself write, on paper or screen, is published in a moment of conscious
                     recognition in his working memory. Second, the author's response to his own self-constructed message then helps him to revise
                     his last utterance and to shape his next utterance. Thus, cybertextually, authors steer or govern their speech internally
                     by a recursive message-feedback cycle. Unconsciously, the author creates a sentence and utters it (a messaging). By witnessing
                     the utterance through his senses, in iconic memory, he first recognizes what he has created. That moment of recognition leads
                     him to construct what he hears or sees (a feedback response). His construction of his own utterance, by reason of being held
                     in working memory, becomes in turn another message to his mind's unselfconscious language-maker that enables him to rewrite
                     or to expand on what he has just uttered. If we fully knew what we were saying in advance of saying it, if we were aware of
                     our entire composition process consciously as it unfolded, there would be no moment of recognition and hence no internal cognitive
                     feedback.
                  </p>
                  
                  <p>The McGurk effect complicates basic cybernetics by showing that every reader authors all messages received by him. Once we
                     realize that every author also gives feedback to all his own messages, that authors and readers behave identically, then cybernetic
                     process becomes cyclic. Uttering, viewed cybertextually, is cognitively recursive, complex, and self-regulatory (or, in Hayles'
                     term, homeostatic). It is recursive because every utterance to the senses (vocalized or written), just by reason of being
                     cognitively modeled, sets in motion an internal mimicking utterance in the speaker's mind. Uttering is complex because a single
                     cybertext proceeds through different channels, one internal and many external, each of which is vulnerable to different types
                     of noise. Uttering is self-regulatory by tending to dampen positive feedback, which accelerates a process beyond what is desired,
                     with negative feedback, which brakes or reverses an action. Positive feedback in cybernetics urges that information density
                     be increased. Negative feedback urges that information density be reduced. Authors govern this density by adding or deleting
                     redundancy. Mechanically, James Watt's flyball governor receives information on the speed of the engine, information that
                     can trigger its slowing down. Even so, the feedback that authors receive from themselves tells them how to revise what they
                     are saying to make it more effective. Positive feedback tells us to repeat and vary; negative feedback, to simplify and condense.
                     This self-monitoring, I argue, is partly available for study with text-analysis tools.
                  </p>
                  
                  
                  <a name="ss1-6-4_h3"></a><h2 class="normal">The Author's Self-monitoring</h2>
                  
                  <p>We now know a great deal about the cognitive mechanics of authoring. It is largely unconscious. Because we cannot remember
                     explicitly how it utters sentences, we have concocted fugitive agents like the Muse to explain creativity. Etymologically,
                     "muse" comes from the Indo-European base for "mind," that is, memory, of which we have several kinds. There is associative long-term episodic and semantic memory, from which
                     we can extract information but can never read through as we do a book. Try as we may by probing long-term memory, in particular,
                     we cannot recover the steps of the uttering process that creates a sentence. On occasion, we make one painstakingly in working
                     memory, a short-term, explicit phonological store with a known capacity, 4 ± 2 items in <a href="#ss1-6-4_b6">Cowan (2000)</a>, revising George Miller's 7 ± 2 items, only as many words as we can utter aloud in two seconds, and confirmed by many experiments since then. The gist
                     behind a sentence taking shape consciously in working memory, however, still comes from a cognitive unknown, "through a glass darkly." We use working memory to rearrange words in such semi-memorized sentences, but the authoring process that suggests them must
                     be queried by a type of memory that we cannot recover as an episode or a semantic meaning. We know from experimentation that
                     people absorb, in the short term, a non-recallable but influential memory of sensory experience. This is not the brief iconic
                     or echoic memory of experience that lasts about 100 microseconds, the space of time between two claps of a hand. We are conscious
                     of these traces. It is the residue they leave in the unconscious, a residue called priming, which is a form of implicit memory
                     lasting several weeks. When we have implicit memory lasting indefinitely in perma-store, we call it procedural memory instead
                     of priming. Here cognitive language processing and other motor skills (like bicycle riding) are stored. Although procedural
                     memories are powerful, we can only recall them by performing them. Why can we not remember, step-by-step, how we make a sentence? The answer seems to be that there is no place in our brain to put the protocol, and maybe no names to identify what goes
                     into it. Its complexity would likely overwhelm working memory many times over. Because we utter easily, we don't really need
                     to know how we do it unless we enjoy frustration and take up stylistics and authorship attribution.
                  </p>
                  
                  <p>The only window of consciousness we have on our language processing is the phonological loop in working memory. Cowan's magic
                     number, "four, plus or minus two" items (2000; cf. Baddeley 1975), governs all our speaking, listening, writing, and reading. What do we know about this humiliating
                     limit? Reading-span tests show that we can recall a range of from 2 to 5.5 final words of a group of unrelated sentences (<a href="#ss1-6-4_b18">Just and Carpenter (1992)</a>): a smaller number, but then we have to deselect all initial words in each sentence. The "word-length" effect shows that the number of items in working memory lessens as their length in syllables increases. We can be confounded
                     at first by garden-path sentences such as "The horse raced past the ancient ruined barn fell" because a key word at the end of a clause (here the verb "fell") takes as subject, not the opportunistic word just preceding, but a noun at the beginning, on the very edge of working-memory
                     capacity. The "articulatory suppression" effect confounds us in another way. If I repeat aloud a nonsense word, "rum-tum, rum-tum, rum-tum," it subvocally captures the working memory of my listeners and prevents them consciously attending to other words. We process
                     words in working memory by drawing on the motor instructions that Broca's area gives to articulate them aloud. Another effect,
                     termed "acoustic similarity," describes our difficulty in recalling a list of similar-sounding words. We can remember semantically related groups like
                     "ghost," "haunt," "sprite," "poltergeist," "specter," "balrog," and "revenant" more easily than simple terms that sound alike, such as "lake," "rack," "trick," "rock," "cake," "coke," and "make." If working memory did not encode words acoustically, we would not experience this trouble.
                  </p>
                  
                  <p>Self-monitoring is partly conscious when taking place in working memory today, principally while we read what we have just
                     written onto a page or word-processed onto a screen. We can only read, however, from five to nine acoustically-encoded items
                     at a time. <a href="#ss1-6-4_b3">Baddeley 2004</a>: (26) shows that recall errors, fewer than two for 9-letter words, more than double for 10-letter words (which must exceed
                     working-memory limits). Only when we can chunk the items into larger units, as in real English words, does the error rate
                     fall. Empirical research into the psychology of reading and writing, which teaches the teachers how to make children literate,
                     reveals that our eyes read by saccades (jumps), fixations, and gazes, that a typical saccade takes twenty milliseconds and
                     covers six—eight letters, and that fixations have a perceptual span of about three characters to the right and fifteen to the left (or
                     four—five words in length) and last 200–300 milliseconds unless they settle into a gaze. College-level students jump and fix their eyes 90 times for every 100 words;
                     one-quarter of those jumps go backwards (<a href="#ss1-6-4_b7">Crowder and Wagner 1992</a>: Table 2.2). Function words get briefer fixations than content words (<a href="#ss1-6-4_b14">Gleason and Ratner 1998</a>: fig. 5.4). We evidently use iconic memory to keep a continuing image of a cybertext before ourselves so that we can free
                     up our working memory for other items, such as higher-level entities than words. It is thought that these entities are propositions,
                     each of which holds an argument and a predicate. Examples of propositions are subject—verb and adjective—noun combinations such as "The sun is a star" and "bright as Venus." The average reading span, calculated to be between six and twelve propositions, that is, between twelve and twenty-four arguments
                     and predicates, can pack a lot into working memory because we can chunk words into higher-level entities. In other words,
                     we form concept maps in which high-level propositions are placeholders for many lower-level items. An item can be a word (argument
                     or predicate), a proposition (a combined argument-predicate), or one or more related propositions.
                  </p>
                  
                  <p>Consider the first two lines in the first quatrain of Shakespeare's sonnet 73. The 18 words in the first two lines cannot
                     fit separately into the phonological loop (PL) working memory (WM) unless they are chunked. Six propositions can do the job
                     (<a href="#ss1-6-4_f3">Figure 23.3</a>).
                  </p>
                  
                  <p>The absolute maximum size of working memory can be as much as ten times four, plus or minus two, but only if words and propositions
                     are fused into a schema. Although these two lines have at least twenty argument-predicate propositions, they can be fitted
                     into the average reading span with some chunking, if working memory handles only propositions 1, 2, 3, 8, 9, and 10, but these
                     are spread out over six levels, some more deeply encoded than others. Of course, chunking becomes easier if the text appears
                     constantly before one's eyes in iconic memory for ready reference. Three quatrains and a couplet would have 21 ± 21 ± 21 ± 10 ± 3 propositions, or 76 in all (within about 125 words), well inside the maximum size of working memory, 40, plus or minus
                     20 basic items, heavily chunked. See <a href="#ss1-6-4_f4">Figure 23.4</a>.
                  </p>
                  
                  <p><br><a name="ss1-6-4_f3"></a>
                     <img src="9781405148641_chapter_23_f3.gif">
                     <b>
                        
                        </b></p>
<p> <b>Figure 23.3 </b> The first quatrain of Shakespeare's sonnet.
                        </p>
                     <br>
                  
                  <p>Three-digit area code and exchange (if chunked to one each), and local number, fall just within working memory for unrelatable
                     numbers. Cybertexts are more heavily redundant than numbers and are integrated syntactically. The maximum reading span for
                     meaningful text would appear to be sonnet-sized, that is, about the length of the Lord's Prayer or the Ten Commandments. The
                     average reading span would cover a shorter span, perhaps a quarter of that, about the amount of text in the 20-word oath like
                     "I do solemnly swear to tell the truth, the whole truth, and nothing but the truth, so help me God." The quantitative limits of working memory in authoring and reading serve an important purpose for cybertextuality: they define
                     the dynamic playing field for an author's <i>currente calamo</i> revisions of his work. In size, this cognitive field covers a quatrain-to-sonnet-sized window of text that shifts forward
                     in jumps, as the author is uttering a text. If we examine how the author manipulates text within this window, we may find
                     some new measures for authorship. They might include the size of the author's uttering window (how many words the author inputs
                     without looking up to absorb them and to generate internal feedback), the types of editorial changes the author carries out
                     inside that window (are they transformative in a syntactic sense, or are they just diction-related?), and the speed with which he moves through the composing process.
                  </p>
                  
                  <p><br><a name="ss1-6-4_f4"></a>
                     <img src="9781405148641_chapter_23_f4.gif">
                     <b>
                        
                        </b></p>
<p> <b>Figure 23.4 </b> Propositions in the first quatrain of Shakespeare's sonnet 73.
                        </p>
                     <br>
                  
                  
                  <a name="ss1-6-4_h4"></a><h2 class="normal">Computer Text Analysis and the Cybertextual Cycle</h2>
                  
                  <p>Traditional stylistics investigates a text spatially as a chain of words that, though it may take time for the reader to traverse,
                     exists complete in a single moment. It has a three-dimensional size on the page but is frozen in time. Most text-analysis
                     programs count the number and frequency of words, phrases, and sentences but do not analyze the text's dynamics as it unfolds.
                     In both making and reading, however, an author has dynamic strategies in revising what he utters, moment by moment. Quantitative
                     information about the frequency and proximity of words and phrases to one another characterizes a whole flat text, or samples
                     of it that are judged representative. However, a text-analysis method captures aspects of the author's cognitive idiolect,
                     such as the ways in which he reacts, positively or negatively, to the feedback that his unselfconscious cognitive modeling
                     gives him. Thus style is partly a function of the author's internal cybertextual message-feedback cycles.
                  </p>
                  
                  <p>My traditional text-analysis studies of Chaucer and Shakespeare highlight features that cognitive processing can explain.
                     Phrase concordancers identify repeated fixed phrases and unfixed collocations in Chaucer's The General Prologue that recur
                     elsewhere in the entire <i>Canterbury Tales</i>. The same holds true of Shakespeare's <i>Troilus and Cressida</i> in his body of work. Their natural vocabularies appear to have been phrasal in nature, comprising units no longer than four,
                     plus or minus two terms, which I called phrasal repetends. <i>Collgen</i>, a program included within <i>TACT</i>, detected them. No repeated phrases exceed in length the capacity of the phonological store of working memory. Their phrasal
                     repetends also form clusters. If we recursively concord a concordance of their repeated words and phrases, we find associative
                     networks. Such clusters must arise from the structure of their long-term memory. I found unusual peaks of overlap in phrasal
                     repetitions between Chaucer's General Prologue and the last tale in the work, the Manciple's (<a href="#ss1-6-4_b19">Lancashire 1993a, 1993b</a>). These clustered repetitions did not arise from subject matter specific to either poem; they belonged to Chaucer's free-floating,
                     current language pool. The shared phrasal repetitions suggest that he wrote the first and the last poem in the <i>Canterbury Tales</i> at about the same time. A comparable overlap ties Shakespeare's <i>Troilus</i> to <i>Hamlet</i> and other plays written in the same period.
                  </p>
                  
                  <p>I analyzed one speech in particular from Shakespeare's problem play, <i>Troilus and Cressida</i>, the Greek leader Agamemnon's disgruntled address to his generals before the walls of Troy (<a href="#ss1-6-4_b21">Lancashire 1999</a>). Without looking for authorial self-monitoring, I found it. This perplexing speech breaks into two mirroring sonnet-sized
                     passages, lines 1–16 and 16–29. Repeated collocations appear in bold, words that occur only once in Shakespeare's vocabulary are in large capital letters,
                     and words that occur twice in small capitals (<a href="#ss1-6-4_f5">Figure 23.5</a>).
                  </p>
                  
                  <p>Shakespeare anchors this two-part speech on five words, all repeated in each part: "princes" and "cheeks," "trial," "action" or "works," and "matter." Each part begins with a question. The right-hand glosses highlight the similar sequence of propositions mirrored in both
                     parts. Despite the novel Latinate words, Shakespeare drew much from associational clusters in his long-term memory. Ten collocations
                     here, each occurring four or more times in his works, form two clusters. One centers on the node word "grow" (7), which collocates with "cheeks" (14), "sap" (7), "knot" (6), "pine" (5), "prince" (5), "veins" (5), and "check" (4) and is found in the first part of his speech. Another centers on the words "winnows" (5) and "wind" (4) in the second part. The word "trial" connects the two parts. Shakespeare seems to have created lines 1–16 in a single dash, then paused, taking it in. His dynamic cognitive field appeared to be about a sonnet in length. Seeing
                     the difficulty of what he had written, he then "explained" it to himself again. Feedback led to repetition with variation within a second identified structured segment, steered by
                     feedback, his recognition and reconstruction of lines 1–16.
                  </p>
                  
                  <p>Feedback governs the information richness of the Agamemnon speech. The first part has six strange words, an acoustic pun ("check" and "cheek"), and almost no repetitions. It is vulnerable to misconstruction by Shakespeare's audience. His satisfaction with the dense
                     imagery and novel language gave him positive feedback and led him to add six neologisms to the second part. Yet doubts about
                     meaning led Shakespeare to negative feedback. And so he introduced redundancy in the form of restatement. He adjusted the
                     rate of information, a cybertext's "entropy" (<a href="#ss1-6-4_b30">Pierce 1961</a>: 80) by simultaneously accelerating and braking the passage's information density. Because written speech lifts the capacity
                     constraints of working memory, and everything Shakespeare wrote remained accessible to his eyes long after uttering, he could
                     allow density to increase. Shakespeare's cybertextual style uses repetition with variation of large units to counterbalance
                     the unrelenting lexical strangeness he cultivates, devising new words, fixing them in striking metaphors. He combines positive
                     and negative feedback.
                  </p>
                  
                  <p><br><a name="ss1-6-4_f5"></a>
                     <img src="9781405148641_chapter_23_f5.gif">
                     <b>
                        
                        </b></p>
<p> <b>Figure 23.5 </b> Chunked six-proposition schema of Shakespeare's sonnet 73.
                        </p>
                     <br>
                  
                  
                  <a name="ss1-6-4_h5"></a><h2 class="normal">A New Philology</h2>
                  
                  <p>Central to old philology are historical linguistics and a literary scholarship that applies what we know about language to
                     the understanding of literature in its historical period. Typical old-philology tools include the concordance and the dictionary.
                     Both read homogeneous, flat, unchanging material texts; and computerized concordancers do not change that fact. New philology
                     supplements this traditional text analysis with tools from cognitive psychology and information science. These include brain-imaging
                     devices and word-processing software like Tech Smith <i>Morae</i>, which records keystrokes, mouse actions, screens, the writer's face, and other events that take place in a composing session.
                     These read dynamic, non-material texts of authors at work in composing. Both old and new philology, when employing computer
                     tools, are cybertextual to the extent that they apply evidence of the author's use of his memory systems, as in self-monitoring
                     and cognitive-feedback processing, to interpret the flat material text that he utters.
                  </p>
                  
                  <p>The most promising applications of the new philology are in the future. It is because the computer workstation can supplement
                     the capacity of working memory that we can observe and measure how an author today responds to his own in-progress, window-by-window
                     uttering of a work. Access to brain-imaging technology is beyond the means of literary researchers without medical qualifications.
                     However, the word-processor enables a writer to solve garden-path sentences, to transform large verbal units (sentences, paragraphs)
                     on the fly, and rapidly to adjust the redundancies he builds into his work. And every event in a word-processed document — continuations, deletions, additions, transpositions — can be time-stamped and counted. Lexical events, especially ones resulting from using online thesauri and lexicons, can be
                     tabulated. Phrasal- and clausal-level events can be described grammatically: passive constructions made active, verb tenses
                     altered, conjuncts replaced by subjuncts, and so on. A new cybertextual stylistics can be based on quantitative information
                     available from the archived word-processing sessions that go into creating a text. Usability software undertakes the kind
                     of archiving that John B. Smith, a pioneer in thematic criticism in English studies, and a process-based writing researcher,
                     applied in his protocol analysis of living writers. Smith believed that asking writers to think aloud as they wrote, a technique
                     Linda Flower introduced, injected noise into that process, and so he used instead a writer's keystrokes, sequences of which
                     he interpreted as actions (<a href="#ss1-6-4_b16">Hayes and Flower 1980</a>). Tracking, replaying, parsing, and displaying the writing process replaced Flower's thinking-aloud protocol. Santos and
                     Badre inferred 73 percent of a writer's mental chunks through automatic analysis of keystrokes (1994: 75). Only semi-automatic
                     analysis could tame the mass of data from such recording sessions.
                  </p>
                  
                  <p><i>Morae</i> offers some of the functionality that Smith describes. Its name, from the Latin term for "delay," names a unit of sound in natural language. The software records keystrokes, mouse actions, screens, the writer's face, and
                     other events that take place in a composing session. This protocol can log each keystroke (including modifying keys) with
                     its elapsed time, and its time of day and date, and can link it to a video of the computer screen as well as to the image
                     of the author at work, at that very moment. A distribution graph of that activity log shows the density of keystrokes at any
                     instant during the keyboarding session. A partial spreadsheet, image, and graph of a <i>Morae</i> session in which I worked on this essay (<a href="#ss1-6-4_f6">Figure 23.6</a>) reveals a rhythmic chunking in the uttering process.
                  </p>
                  
                  <p>A <i>Morae</i> graph can be exported to a spreadsheet for analysis; and one can play back, in a sequence of recorded sessions, the making
                     of an entire work. These record cybertextual self-monitoring at work.
                  </p>
                  
                  <p>Even one recording session by a Shakespeare or a James Joyce would be invaluable evidence of the author's cognitive self-monitoring
                     while composing. Their habits, of course, can only be inferred from texts and foul papers. For most writers, we do not even
                     have the equivalent of Joyce's extraordinary notebooks, such as the well-known "Circe 3" (1972: 278–83) from <i>Ulysses</i>, which holds his brief notes in vertical and horizontal lists, many crossed out in colored crayon after he used them in revision.
                     It is hard to resist interpreting Joyce's notes, most of which fall between one and nine words, as direct, cognitively chunked
                     deposits from his limited-capacity, very human working memory. Short lyrics, especially the 14-line sonnet, may also remain
                     the most popular verse forms because of cognitive chunking: they can hold the maximum number of propositions that we can consciously
                     encode in memory. Yet the truth is that we will never know how the minds of these writers worked. If present and future writers,
                     however, record their authoring sessions and donate them, with their letters and papers, for study, critics bent on text analysis,
                     close reading, and stylistics will inherit a windfall of data and new measures. Cybertextuality then will be a widely testable
                     theory.
                  </p>
                  
                  <p><br><a name="ss1-6-4_f6"></a>
                     <img src="9781405148641_chapter_23_f6.gif">
                     <b>
                        
                        </b></p>
<p> <b>Figure 23.6 </b> Part of my writing session in Morae.
                        </p>
                     <br>
                  
                  
                  
                  
                  <a name="ss1-6-4_h6"></a><h2 class="normal">Selected References</h2>
                  <a name="ss1-6-4_b1"></a><p class="hang">Aarseth, Espen J. (1997). <i><span class="title">Cybertext: Perspectives on Ergodic Literature</span></i>. Baltimore: Johns Hopkins University Press.
                  </p>
                  <a name="ss1-6-4_b2"></a><p class="hang">Baddeley, Alan (2003). "<i><span class="title">Working Memory and Language: An Overview.</span></i>" <i><span class="title">Journal of Communication Disorders</span></i> 36.3: 189–203.
                  </p>
                  <a name="ss1-6-4_b3"></a><p class="hang">Baddeley, Alan (2004). <i><span class="title">Your Memory: A User's Guide</span></i>. New Illustrated Edition. Richmond Hill, Ontario: Firefly Books.
                  </p>
                  <a name="ss1-6-4_b4"></a><p class="hang">Baddeley, Alan, Neil Thomson, and Mary Buchanan (1975). "<i><span class="title">Word Length and the Structure of Short-term Memory.</span></i>" <i><span class="title">Journal of Verbal Learning and Verbal Behavior</span></i> 14.6: 575–89.
                  </p>
                  <a name="ss1-6-4_b5"></a><p class="hang">Carpenter, Rollo (2006). <i><span class="title">Jabberwacky</span></i>. Icogno. URL: &lt;<a href="http://www.jabberwacky.com">http://www.jabberwacky.com</a>&gt;. Accessed May 8, 2006.
                  </p>
                  <a name="ss1-6-4_b6"></a><p class="hang">Cowan, Nelson (2000). "<i><span class="title">The Magical Number 4 in Short-term Memory: A Reconsideration of Mental Storage Capacity.</span></i>" <i><span class="title">Behavioural and Brain Sciences</span></i> 24: 87–185.
                  </p>
                  <a name="ss1-6-4_b7"></a><p class="hang">Crowder, Robert G., and Richard K. Wagner (1992). <i><span class="title">The Psychology of Reading: An Introduction</span></i>. New York: Oxford University Press.
                  </p>
                  <a name="ss1-6-4_b8"></a><p class="hang">Dunning, Alastair (2000). "<i><span class="title">Recounting Digital Tales: Chaucer Scholarship and The Canterbury Tales Project.</span></i>" <i><span class="title">Arts and Humanities Data Service</span></i>. &lt;<a href="http://ahds.ac.uk/creating/case-studies/canterbury/">http://ahds.ac.uk/creating/case-studies/canterbury/</a>&gt;.
                  </p>
                  <a name="ss1-6-4_b9"></a><p class="hang">ePresence Consortium (2006). <i><span class="title">ePresence Interactive Media</span></i>. University of Toronto: Knowledge Media Design Institute. &lt;<a href="http://epresence.tv/mediaContent/default.aspx">http://epresence.tv/mediaContent/default.aspx</a>&gt;. Accessed May 8, 2006.
                  </p>
                  <a name="ss1-6-4_b10"></a><p class="hang">Federman, Mark (2004). "<i><span class="title">What is the Meaning of The Medium is the Message?</span></i>" &lt;<a href="http://individual.utoronto.ca/markfederman/article_mediumisthemessage.htm">http://individual.utoronto.ca/markfederman/article_mediumisthemessage.htm</a>&gt;. Accessed May 8, 2006.
                  </p>
                  <a name="ss1-6-4_b11"></a><p class="hang">Galison, Peter (1994). "<i><span class="title">The Ontology of the Enemy: Norbert Weiner and the Cybernetic Vision.</span></i>" <i><span class="title">Critical Inquiry</span></i> 21: 228–66.
                  </p>
                  <a name="ss1-6-4_b12"></a><p class="hang">Garrard, Peter, L. M. Maloney, J. R. Hodges, and K. Patterson (2005). "<i><span class="title">The Effects of Very Early Alzheimer's Disease on the Characteristics of Writing by a Renowned Author.</span></i>" <i><span class="title">Brain</span></i> 128.2: 250–60.
                  </p>
                  <a name="ss1-6-4_b13"></a><p class="hang">Geschwind, Norman (1979). "<i><span class="title">Specializations of the Human Brain.</span></i>" <i><span class="title">The Brain</span></i>. A Scientific American Book. San Francisco: W. H. Freeman, pp. 108–17. 
                  </p>
                  <a name="ss1-6-4_b14"></a><p class="hang">Gleason, Jean Burko, and Nan Bernstein Ratner (Eds.) (1998). <i><span class="title">Psycholinguistics</span></i>, 2nd edn. Fort Worth: Harcourt Brace.
                  </p>
                  <a name="ss1-6-4_b15"></a><p class="hang">Haraway, Donna (1985). "<i><span class="title">A Manifesto for Cyborgs: Science, Technology, and Socialist Feminism in the 1980s.</span></i>" <i><span class="title">Socialist Review</span></i> 80: 65–108.
                  </p>
                  <a name="ss1-6-4_b16"></a><p class="hang">Hayes, J. R., and L. S. Flower (1980). "<i><span class="title">Identifying the Organization of Writing Processes.</span></i>" In L. W. Gregg and E. R. Steinberg (Eds.). <i><span class="title">Cognitive Processes in Writing</span></i>. Hillsdale, NJ: Lawrence Erlbaum.
                  </p>
                  <a name="ss1-6-4_b17"></a><p class="hang">Hayles, N. Katherine (1999). <i><span class="title">How We Became Post-human: Virtual Bodies in Cybernetics, Literature, and Informatics</span></i>. Chicago: University of Chicago Press.
                  </p>
                  <a name="ss1-6-4_b18"></a><p class="hang">Just, Marcel A., and Patricia A. Carpenter (1992). "<i><span class="title">A Capacity Theory of Comprehension: Individual Differences in Working Memory.</span></i>" <i><span class="title">Psychological Review</span></i> 99: 122–49.
                  </p>
                  <a name="ss1-6-4_b19"></a><p class="hang">Lancashire, Ian (1993a). "<i><span class="title">Chaucer's Phrasal Repetends and <i>The Manciple's Prologue and Tale</i>.</span></i>" In <i><span class="title"><i>Computer-Based Chaucer Studies</i>. CCHWP 3</span></i>. Toronto: Centre for Computing in the Humanities, pp. 99–122. 
                  </p>
                  <a name="ss1-6-4_b20"></a><p class="hang">Lancashire, Ian (1993b). "<i><span class="title">Chaucer's Repetends from The General Prologue of <i>The Canterbury Tales</i>.</span></i>" In <i><span class="title">The Centre and its Compass: Studies in Medieval Literature in Honor of Professor John Leyerle</span></i>. Kalamazoo, MI: Western Michigan University, pp. 315–65. 
                  </p>
                  <a name="ss1-6-4_b21"></a><p class="hang">Lancashire, Ian (1999). "<i><span class="title">Probing Shakespeare's Idiolect in <i>Troilus and Cressida</i> I.3.1–29.</span></i>" <i><span class="title">University of Toronto Quarterly</span></i> 68.3: 728–67.
                  </p>
                  <a name="ss1-6-4_b22"></a><p class="hang">Lancashire, Ian (2004). "<i><span class="title">Cybertextuality.</span></i>" <i><span class="title">TEXT Technology</span></i> 1–18.
                  </p>
                  <a name="ss1-6-4_b23"></a><p class="hang">Lancashire, Ian (2005). "<i><span class="title">Cognitive Stylistics and the Literary Imagination.</span></i>" <i><span class="title">Companion to Digital Humanities</span></i>. Cambridge: Cambridge University Press, pp. 397–414. 
                  </p>
                  <a name="ss1-6-4_b24"></a><p class="hang">Lieberman, Philip (2000). <i><span class="title">Human Language and Our Reptilian Brain: The Subcortical Bases of Speech, Syntax, and Thought</span></i>. Cambridge, MA: Harvard University Press.
                  </p>
                  <a name="ss1-6-4_b25"></a><p class="hang">Liu, Hugo, and Push Singh (2002). "<i><span class="title">MAKEBE-LIEVE: Using Commonsense Knowledge to Generate Stories.</span></i>" <i><span class="title">Proceedings of the Eighteenth National Conference on Artificial Intelligence, AAAI 2002</span></i>. Edmonton: AAAI Press, pp. 957–58. &lt;<a href="http://agents.media.mit.edu/projects/makebelieve/">http://agents.media.mit.edu/projects/makebelieve/</a>&gt;.
                  </p>
                  <a name="ss1-6-4_b26"></a><p class="hang">Lyotard, Jean François (1984). <i><span class="title">The Postmodern Condition: A Report on Knowledge (</span></i>Geoff Bennington and Brian Massumi, Trans.). Minneapolis: University of Minnesota Press.
                  </p>
                  <a name="ss1-6-4_b27"></a><p class="hang">Masani, R. P. (1990). <i><span class="title">Norbert Wiener 1894–1964</span></i>. Basel: Birkhäuser.
                  </p>
                  <a name="ss1-6-4_b28"></a><p class="hang">McGurk, H., and J. MacDonald (1976). "<i><span class="title">Hearing Lips and Seeing Voices.</span></i>" <i><span class="title">Nature</span></i> 263: 747–8.
                  </p>
                  <a name="ss1-6-4_b29"></a><p class="hang">Miller, G. A. (1956). "<i><span class="title">The Magical Number Seven, plus or minus Two: Some Limits on our Capacity for Processing Information.</span></i>" <i><span class="title">Psychological Review</span></i> 63: 89–97.
                  </p>
                  <a name="ss1-6-4_b30"></a><p class="hang">Pierce, John R. (1961). <i><span class="title">An Introduction to Information Theory: Symbols, Signals &amp; Noise</span></i>, 2nd edn. New York: Dover, 1980.
                  </p>
                  <a name="ss1-6-4_b31"></a><p class="hang">Sachs, Stephen (2006). <i><span class="title">The Jumbler</span></i>. &lt;<a href="http://www.stevesachs.com/jumbler.cgi">http://www.stevesachs.com/jumbler.cgi</a>&gt;. Accessed May 8, 2006.
                  </p>
                  <a name="ss1-6-4_b32"></a><p class="hang">Santos, Paulo J., and Albert N. Badre (1994). "<i><span class="title">Automatic Chunk Detection in Human-computer Interaction.</span></i>" <i><span class="title">Proceedings of the Workshop on Advanced Visual Interfaces</span></i>. New York: ACM, pp. 69–77. 
                  </p>
                  <a name="ss1-6-4_b33"></a><p class="hang">Smith, John B., Dana Kay Smith, and Eileen Kupstas (1993). "<i><span class="title">Automated Protocol Analysis.</span></i>" <i><span class="title">Human–computer Interaction</span></i> 8: 101–45.
                  </p>
                  <a name="ss1-6-4_b34"></a><p class="hang">Stribling, Jeremy, Max Krohn, and Dan Aguayo (2006). <i><span class="title">SCIgen – An Automatic CS Paper Generator</span></i>. Cambridge, MA: Computer Science and Artificial Intelligence Laboratory, MIT. &lt;<a href="http://pdos.csail.mit.edu/scigen/">http://pdos.csail.mit.edu/scigen/</a>&gt;. Accessed May 8, 2006.
                  </p>
                  <a name="ss1-6-4_b35"></a><p class="hang">TechSmith (2006). <i><span class="title">Morae Usability Testing for Software and Web Sites</span></i>. Okemos, MI. &lt;<a href="http://www.tech-smith.com/morae.asp">http://www.tech-smith.com/morae.asp</a>&gt;. Accessed May 8, 2006.
                  </p>
                  <a name="ss1-6-4_b36"></a><p class="hang">Watt, Robert (2004). <i><span class="title">Concordance. Version 3.2</span></i>. &lt;<a href="http://www.concordancesoftware.co.uk/">http://www.concordancesoftware.co.uk/</a>&gt;. Accessed May 8, 2006.
                  </p>
                  <a name="ss1-6-4_b37"></a><p class="hang">Wiener, Norbert (1948). <i><span class="title">Cybernetics or Control and Communication in the Animal and the Machine</span></i>, 2nd edn. Cambridge, MA: MIT Press, 1961.
                  </p>
                  <a name="ss1-6-4_b38"></a><p class="hang">Wiener, Norbert (1950). <i><span class="title">The Human Use of Human Beings: Cybernetics and Society</span></i>. New York: Hearst, 1967.
                  </p>
                  
                  
                  
               </div>
            
